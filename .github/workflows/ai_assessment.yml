name: Assess PR Risk

on:
  pull_request:
    types: [opened, reopened]

# References: https://circuit.cisco.com/app/home
#
permissions:
  contents: read
  pull-requests: write

jobs:
  analyze-diff:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/ai-requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Create ai-requirements.txt
        run: |
          echo "langchain" > ai-requirements.txt
          echo "langchain-google-genai" >> ai-requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ai-requirements.txt

      - name: Get PR diff
        id: get-diff
        run: |
          # Get the PR diff and save it to a file
          git diff ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} > pr_diff.txt
          echo "diff_size=$(stat -c%s pr_diff.txt)" >> $GITHUB_OUTPUT

      - name: Create Python analysis script
        run: |
          cat > analyze_pr.py << 'EOF_PYTHON_SCRIPT'
          import os
          from langchain.chat_models import init_chat_model # Requested import
          from langchain_core.messages import HumanMessage # Needed for chat model input

          # Read the PR diff
          pr_diff_file = "pr_diff.txt"
          if not os.path.exists(pr_diff_file):
              print(f"Error: {pr_diff_file} not found.")
              exit(1)
          with open(pr_diff_file, "r") as f:
              pr_diff = f.read()

          pr_description_file = "pr_description.txt"
          pr_description = ""
          if os.path.exists(pr_description_file):
              with open(pr_description_file, "r") as f:
                  pr_description = f.read()
          else:
              print(f"Warning: {pr_description_file} not found. PR description will be empty.")

          # Get other PR context from environment variables
          pr_title = os.environ.get("PR_TITLE", "No title provided")
          pr_number = os.environ.get("PR_NUMBER", "N/A")
          github_repository = os.environ.get("GITHUB_REPOSITORY", "Unknown/Unknown")

          # Construct the prompt for the LLM
          prompt = f"""
          You are an AI assistant tasked with assessing the risk of changes introduced in a GitHub Pull Request.
          Analyze the following PR diff and provide a concise risk assessment.
          Consider potential impacts on stability, security, performance, and maintainability.
          Output your assessment in Markdown format, clearly stating the risk level (e.g., Low, Medium, High).
          Provide a summary of the changes and then the risk assessment with justifications.

          GitHub Repository: {github_repository}
          Pull Request Number: {pr_number}
          Pull Request Title: {pr_title}
 
          ---
          PR Description:
          {pr_description if pr_description else "No description provided."}
          ---

          ---
          PR Diff:
          {pr_diff}
          ---

          Risk Assessment:
          """

          # Initialize the Generative Model using LangChain
          model_name_lc = "gemini-2.0-flash" # Using the requested model
          try:
              # LangChain's init_chat_model will automatically pick up GOOGLE_API_KEY from environment variables
              model = init_chat_model(model_name_lc, model_provider="google_genai")
          except Exception as e:
              print(f"Error initializing model '{model_name_lc}': {e}")
              with open("llm_analysis.md", "w") as f:
                  f.write(f"Error: Could not initialize LLM ({model_name_lc}). Please check model availability and API key permissions.")
              exit(1)

          llm_analysis = ""
          try:
              # Generate content using the LangChain chat model
              # Chat models expect a list of messages. For a single prompt, use HumanMessage.
              response = model.invoke([HumanMessage(content=prompt)])
              llm_analysis = response.content # Extract the content from the AI message
          except Exception as e:
              llm_analysis = f"Error during LLM analysis: {e}\n\n" \
                             f"Please check the GOOGLE_API_KEY, model capabilities, and input size."
              print(f"Error during LLM analysis: {e}")

          # Write the analysis to a file
          with open("llm_analysis.md", "w") as f:
              f.write(llm_analysis)

          print("LLM analysis complete and saved to llm_analysis.md")
          EOF_PYTHON_SCRIPT

      - name: Analyze diff with LLM
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
          LANGSMITH_PROJECT: ${{ secrets.LANGSMITH_PROJECT }}
          LANGSMITH_TRACING: true
          GITHUB_REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          PR_TITLE: ${{ github.event.pull_request.title }}
        run: python analyze_pr.py

      - name: Add LLM analysis as PR comment
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const analysis = fs.readFileSync('llm_analysis.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## LLM Analysis of PR Changes\n\n${analysis}`
            })
